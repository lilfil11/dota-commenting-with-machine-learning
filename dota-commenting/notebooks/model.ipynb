{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f7c1cd",
   "metadata": {
    "papermill": {
     "duration": 0.005124,
     "end_time": "2025-05-02T19:35:52.075001",
     "exception": false,
     "start_time": "2025-05-02T19:35:52.069877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8552d7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-02T19:35:52.085543Z",
     "iopub.status.busy": "2025-05-02T19:35:52.085127Z",
     "iopub.status.idle": "2025-05-02T19:36:03.485534Z",
     "shell.execute_reply": "2025-05-02T19:36:03.484798Z"
    },
    "papermill": {
     "duration": 11.407447,
     "end_time": "2025-05-02T19:36:03.487124",
     "exception": false,
     "start_time": "2025-05-02T19:35:52.079677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from collections import Counter\n",
    "\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd368ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:36:03.497746Z",
     "iopub.status.busy": "2025-05-02T19:36:03.497365Z",
     "iopub.status.idle": "2025-05-02T19:36:03.581595Z",
     "shell.execute_reply": "2025-05-02T19:36:03.580827Z"
    },
    "papermill": {
     "duration": 0.090875,
     "end_time": "2025-05-02T19:36:03.582879",
     "exception": false,
     "start_time": "2025-05-02T19:36:03.492004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "# Проверка доступности GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Используемое устройство: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361fb2b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:36:03.593475Z",
     "iopub.status.busy": "2025-05-02T19:36:03.593149Z",
     "iopub.status.idle": "2025-05-02T19:36:03.596600Z",
     "shell.execute_reply": "2025-05-02T19:36:03.595873Z"
    },
    "papermill": {
     "duration": 0.009933,
     "end_time": "2025-05-02T19:36:03.597845",
     "exception": false,
     "start_time": "2025-05-02T19:36:03.587912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Конфигурация\n",
    "DATA_DIR = '/kaggle/input/dota-2-comments'\n",
    "FRAMES_PER_VIDEO = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c54ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:36:03.607574Z",
     "iopub.status.busy": "2025-05-02T19:36:03.607348Z",
     "iopub.status.idle": "2025-05-02T19:36:03.611487Z",
     "shell.execute_reply": "2025-05-02T19:36:03.610663Z"
    },
    "papermill": {
     "duration": 0.010273,
     "end_time": "2025-05-02T19:36:03.612668",
     "exception": false,
     "start_time": "2025-05-02T19:36:03.602395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Словарь для сортировки видео\n",
    "order_dict = {\n",
    "    '2396917974_5': 1,\n",
    "    '2396917974_2': 2,\n",
    "    '2406178117_1': 3,\n",
    "    '2406178117_2': 4,\n",
    "    '2406178117_3': 5,\n",
    "    '2406178117_4': 6,\n",
    "    '2406178117_5': 7,\n",
    "    '2406178117_6': 8,\n",
    "    '2406178117_7': 9,\n",
    "    '2406178117_8': 10,\n",
    "    '2406178117_9': 11,\n",
    "    '2382667658_1': 12,\n",
    "    '2382667658_2': 13,\n",
    "    '2382667658_3': 14,\n",
    "    '2382667658_4': 15,\n",
    "    '2382667658_5': 16,\n",
    "    '2382667658_6': 17,\n",
    "    '2382667658_7': 18,\n",
    "    '2382667658_8': 19,\n",
    "    '2392353636_1': 20,\n",
    "    '2392353636_2': 21\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec3fd2",
   "metadata": {
    "papermill": {
     "duration": 0.004258,
     "end_time": "2025-05-02T19:36:03.621480",
     "exception": false,
     "start_time": "2025-05-02T19:36:03.617222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d00b7ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:36:03.631370Z",
     "iopub.status.busy": "2025-05-02T19:36:03.631097Z",
     "iopub.status.idle": "2025-05-02T19:37:19.850590Z",
     "shell.execute_reply": "2025-05-02T19:37:19.849680Z"
    },
    "papermill": {
     "duration": 76.233756,
     "end_time": "2025-05-02T19:37:19.859691",
     "exception": false,
     "start_time": "2025-05-02T19:36:03.625935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 2663\n"
     ]
    }
   ],
   "source": [
    "# Датасет\n",
    "class Dota2Dataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        self.word_freq = Counter()\n",
    "        \n",
    "        # Проходим по всем папкам с видео\n",
    "        for video_id in sorted(os.listdir(data_dir), key=lambda video_id: order_dict[video_id]):\n",
    "            id_dir = os.path.join(data_dir, video_id)\n",
    "            for video_dir in sorted(os.listdir(id_dir), key=lambda video_dir: int(video_dir)):\n",
    "                video_path = os.path.join(id_dir, video_dir)\n",
    "                if not os.path.isdir(video_path):\n",
    "                    continue\n",
    "                    \n",
    "                # Загружаем кадры\n",
    "                frames_dir = os.path.join(video_path, \"frames\")\n",
    "                frame_paths = [\n",
    "                    os.path.join(frames_dir, f) \n",
    "                    for f in sorted(os.listdir(frames_dir), key=lambda x: int(x.split('.')[0])) if not int(f.split('.')[0]) % 2\n",
    "                ]\n",
    "                \n",
    "                # Загружаем комментарии\n",
    "                labels_path = os.path.join(video_path, \"labels.txt\")\n",
    "                with open(labels_path, 'r', encoding='utf-8') as f:\n",
    "                    captions = f.read().strip().split('\\n')\n",
    "            \n",
    "                # Токенизируем комментарии и обновляем частоту слов\n",
    "                tokenized_captions = []\n",
    "                for cap in captions:\n",
    "                    tokens = word_tokenize(cap.lower())\n",
    "                    self.word_freq.update(tokens)\n",
    "                    tokenized_captions.append(tokens)\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'video_id': video_dir,\n",
    "                    'frame_paths': frame_paths,\n",
    "                    'captions': captions,\n",
    "                    'tokenized_captions': tokenized_captions\n",
    "                })\n",
    "        \n",
    "        # Создаем словарь\n",
    "        self.vocab = ['<pad>', '<start>', '<end>', '<unk>'] + \\\n",
    "                     [word for word, freq in self.word_freq.items() if freq >= 5]\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: word for idx, word in enumerate(self.vocab)}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Загружаем и преобразуем кадры\n",
    "        frames = []\n",
    "        for frame_path in sample['frame_paths']:\n",
    "            img = Image.open(frame_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            frames.append(img)\n",
    "        frames = torch.stack(frames)\n",
    "        \n",
    "        # Преобразуем комментарии в индексы\n",
    "        caption_indices = []\n",
    "        for tokens in sample['tokenized_captions']:\n",
    "            indices = [self.word2idx.get(token, self.word2idx['<unk>']) for token in tokens]\n",
    "            indices = [self.word2idx['<start>']] + indices + [self.word2idx['<end>']]\n",
    "            caption_indices.append(torch.tensor(indices, dtype=torch.long))\n",
    "        \n",
    "        return {\n",
    "            'video_id': sample['video_id'],\n",
    "            'frames': frames,                    # [10, 3, 224, 224] <-> [N, C, H, W]\n",
    "            'captions': sample['captions'],\n",
    "            'caption_indices': caption_indices\n",
    "        }\n",
    "\n",
    "# Трансформации для изображений\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Загружаем датасет\n",
    "dataset = Dota2Dataset(DATA_DIR, transform=transform)\n",
    "vocab_size = dataset.vocab_size\n",
    "print(f\"Размер словаря: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af07f1df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:19.876660Z",
     "iopub.status.busy": "2025-05-02T19:37:19.876351Z",
     "iopub.status.idle": "2025-05-02T19:37:20.188310Z",
     "shell.execute_reply": "2025-05-02T19:37:20.187403Z"
    },
    "papermill": {
     "duration": 0.32239,
     "end_time": "2025-05-02T19:37:20.190019",
     "exception": false,
     "start_time": "2025-05-02T19:37:19.867629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video_id:\t 2\n",
      "Frames.size:\t torch.Size([10, 3, 224, 224])\n",
      "Captions:\t ['В памяти было шесть игр, пять выиграл, в составе было супер-потное против спирит, но не сло. Да, тут, конечно, нужно понимать, что демордж...']\n",
      "Indices:\t [tensor([ 1, 28,  3, 29,  3, 30,  4, 31, 32,  4, 28,  3, 29,  3, 33, 34,  4, 35,\n",
      "        20,  3,  8,  9,  4, 36,  4, 37,  4, 38, 39,  4, 40,  3, 41,  2])]\n"
     ]
    }
   ],
   "source": [
    "# Пример объекта выборки\n",
    "example = dataset[1]\n",
    "\n",
    "print('Video_id:\\t', example['video_id'])\n",
    "print('Frames.size:\\t', example['frames'].size())\n",
    "print('Captions:\\t', example['captions'])\n",
    "print('Indices:\\t', example['caption_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367bf3f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:20.208976Z",
     "iopub.status.busy": "2025-05-02T19:37:20.208567Z",
     "iopub.status.idle": "2025-05-02T19:37:20.218123Z",
     "shell.execute_reply": "2025-05-02T19:37:20.217322Z"
    },
    "papermill": {
     "duration": 0.020437,
     "end_time": "2025-05-02T19:37:20.219398",
     "exception": false,
     "start_time": "2025-05-02T19:37:20.198961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Разделяем на тренировочную и валидационную выборки\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d32ae",
   "metadata": {
    "papermill": {
     "duration": 0.004468,
     "end_time": "2025-05-02T19:37:20.228690",
     "exception": false,
     "start_time": "2025-05-02T19:37:20.224222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Извлечение признаков из кадров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a489cf79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:20.240993Z",
     "iopub.status.busy": "2025-05-02T19:37:20.240589Z",
     "iopub.status.idle": "2025-05-02T19:37:21.593957Z",
     "shell.execute_reply": "2025-05-02T19:37:21.593170Z"
    },
    "papermill": {
     "duration": 1.36211,
     "end_time": "2025-05-02T19:37:21.595530",
     "exception": false,
     "start_time": "2025-05-02T19:37:20.233420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:00<00:00, 193MB/s]\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        effnet = models.efficientnet_v2_s(pretrained=True)\n",
    "        modules = list(effnet.children())[:-2]  # Удаляем avgpool и fc слои\n",
    "        self.effnet = nn.Sequential(*modules)\n",
    "        \n",
    "        for param in self.effnet.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, images):\n",
    "        # images: [batch_size, num_frames, num_channels, height, weight]\n",
    "        batch_size, num_frames = images.size(0), images.size(1)\n",
    "        images = images.view(-1, *images.size()[2:])\n",
    "        out = self.effnet(images)\n",
    "        return out.view(batch_size, num_frames, 1280, 7, 7).permute(0, 1, 3, 4, 2)\n",
    "\n",
    "encoder = Encoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be251566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:21.606593Z",
     "iopub.status.busy": "2025-05-02T19:37:21.606356Z",
     "iopub.status.idle": "2025-05-02T19:37:22.902007Z",
     "shell.execute_reply": "2025-05-02T19:37:22.901119Z"
    },
    "papermill": {
     "duration": 1.30273,
     "end_time": "2025-05-02T19:37:22.903381",
     "exception": false,
     "start_time": "2025-05-02T19:37:21.600651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7, 7, 1280])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(dataset[1]['frames'].unsqueeze(0).to(device)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4303059",
   "metadata": {
    "papermill": {
     "duration": 0.005088,
     "end_time": "2025-05-02T19:37:22.913820",
     "exception": false,
     "start_time": "2025-05-02T19:37:22.908732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Модель генерации комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaeeb68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:22.925181Z",
     "iopub.status.busy": "2025-05-02T19:37:22.924917Z",
     "iopub.status.idle": "2025-05-02T19:37:22.930588Z",
     "shell.execute_reply": "2025-05-02T19:37:22.929820Z"
    },
    "papermill": {
     "duration": 0.012953,
     "end_time": "2025-05-02T19:37:22.931893",
     "exception": false,
     "start_time": "2025-05-02T19:37:22.918940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)  # linear layer to transform encoded image\n",
    "        self.decoder_att = nn.Linear(decoder_dim, attention_dim)  # linear layer to transform decoder's output\n",
    "        self.full_att = nn.Linear(attention_dim, 1)  # linear layer to calculate values to be softmax-ed\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)  # softmax layer to calculate weights\n",
    "\n",
    "    def forward(self, encoder_out, decoder_hidden):\n",
    "        att1 = self.encoder_att(encoder_out)  # (batch_size, num_pixels, attention_dim)\n",
    "        att2 = self.decoder_att(decoder_hidden)  # (batch_size, attention_dim)\n",
    "        att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2)  # (batch_size, num_pixels)\n",
    "        alpha = self.softmax(att)  # (batch_size, num_pixels)\n",
    "        attention_weighted_encoding = (encoder_out * alpha.unsqueeze(2)).sum(dim=1)  # (batch_size, encoder_dim)\n",
    "\n",
    "        return attention_weighted_encoding, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63baf29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:22.943112Z",
     "iopub.status.busy": "2025-05-02T19:37:22.942879Z",
     "iopub.status.idle": "2025-05-02T19:37:22.953944Z",
     "shell.execute_reply": "2025-05-02T19:37:22.953264Z"
    },
    "papermill": {
     "duration": 0.018312,
     "end_time": "2025-05-02T19:37:22.955478",
     "exception": false,
     "start_time": "2025-05-02T19:37:22.937166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderWithAttention(nn.Module):\n",
    "    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, encoder_dim=1280, dropout=0.5):\n",
    "        super(DecoderWithAttention, self).__init__()\n",
    "\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.attention = Attention(encoder_dim, decoder_dim, attention_dim) \n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim) \n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.decode_step = nn.LSTMCell(embed_dim + encoder_dim, decoder_dim, bias=True) \n",
    "        self.init_h = nn.Linear(encoder_dim, decoder_dim) \n",
    "        self.init_c = nn.Linear(encoder_dim, decoder_dim) \n",
    "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc = nn.Linear(decoder_dim, vocab_size)  \n",
    "        self.init_weights()  \n",
    "\n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def init_hidden_state(self, encoder_out):\n",
    "        mean_encoder_out = encoder_out.mean(dim=1)\n",
    "        h = self.init_h(mean_encoder_out)  # (batch_size, decoder_dim)\n",
    "        c = self.init_c(mean_encoder_out)\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths):\n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "\n",
    "        encoder_out = encoder_out.reshape(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        num_pixels = encoder_out.size(1)\n",
    "\n",
    "        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim=0, descending=True)\n",
    "        encoder_out = encoder_out[sort_ind]\n",
    "        encoded_captions = encoded_captions[sort_ind]\n",
    "\n",
    "        embeddings = self.embedding(encoded_captions)  # (batch_size, max_caption_length, embed_dim)\n",
    "        h, c = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
    "\n",
    "        decode_lengths = (caption_lengths - 1).tolist()\n",
    "\n",
    "        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(device)\n",
    "        alphas = torch.zeros(batch_size, max(decode_lengths), num_pixels).to(device)\n",
    "\n",
    "        for t in range(max(decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in decode_lengths])\n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],\n",
    "                                                                h[:batch_size_t])\n",
    "            gate = self.sigmoid(self.f_beta(h[:batch_size_t])) \n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "            h, c = self.decode_step(\n",
    "                torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1),\n",
    "                (h[:batch_size_t], c[:batch_size_t]))\n",
    "            preds = self.fc(self.dropout(h))  \n",
    "            predictions[:batch_size_t, t, :] = preds\n",
    "            alphas[:batch_size_t, t, :] = alpha\n",
    "\n",
    "        return predictions, encoded_captions, decode_lengths, alphas, sort_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e78e3",
   "metadata": {
    "papermill": {
     "duration": 0.007864,
     "end_time": "2025-05-02T19:37:22.970716",
     "exception": false,
     "start_time": "2025-05-02T19:37:22.962852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54f3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:22.982260Z",
     "iopub.status.busy": "2025-05-02T19:37:22.981955Z",
     "iopub.status.idle": "2025-05-02T19:37:22.991628Z",
     "shell.execute_reply": "2025-05-02T19:37:22.990916Z"
    },
    "papermill": {
     "duration": 0.016675,
     "end_time": "2025-05-02T19:37:22.992854",
     "exception": false,
     "start_time": "2025-05-02T19:37:22.976179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(scores, targets, k):\n",
    "    batch_size = targets.size(0)\n",
    "    _, ind = scores.topk(k, 1, True, True)\n",
    "    correct = ind.eq(targets.view(-1, 1).expand_as(ind))\n",
    "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
    "    return correct_total.item() * (100.0 / batch_size)\n",
    "\n",
    "def clip_gradient(optimizer, grad_clip):\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Обработка кадров\n",
    "    frames = [item['frames'] for item in batch]\n",
    "    frames = torch.stack(frames)\n",
    "    \n",
    "    # Обработка комментариев\n",
    "    captions = [cap for item in batch for cap in item['caption_indices']]\n",
    "    caption_lengths = torch.tensor([len(cap) for cap in captions])\n",
    "    \n",
    "    # Дополняем комментарии до одинаковой длины\n",
    "    captions_padded = pad_sequence(captions, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return frames, captions_padded, caption_lengths.unsqueeze(1), [item['captions'] for item in batch]\n",
    "\n",
    "def save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, decoder_optimizer,\n",
    "                    bleu4, is_best):\n",
    "    state = {'epoch': epoch,\n",
    "             'epochs_since_improvement': epochs_since_improvement,\n",
    "             'bleu-4': bleu4,\n",
    "             'encoder': encoder,\n",
    "             'decoder': decoder,\n",
    "             'decoder_optimizer': decoder_optimizer}\n",
    "    filename = 'checkpoint_' + data_name + '.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
    "    if is_best:\n",
    "        torch.save(state, 'BEST_' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4b799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:23.003815Z",
     "iopub.status.busy": "2025-05-02T19:37:23.003596Z",
     "iopub.status.idle": "2025-05-02T19:37:23.009545Z",
     "shell.execute_reply": "2025-05-02T19:37:23.008940Z"
    },
    "papermill": {
     "duration": 0.012727,
     "end_time": "2025-05-02T19:37:23.010769",
     "exception": false,
     "start_time": "2025-05-02T19:37:22.998042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, encoder, decoder, criterion, decoder_optimizer, epoch):\n",
    "    decoder.train() \n",
    "    losses = AverageMeter() \n",
    "    top5accs = AverageMeter() \n",
    "\n",
    "    for i, (imgs, caps, caplens, _) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        caps = caps.to(device)\n",
    "        caplens = caplens.to(device)\n",
    "\n",
    "        imgs = encoder(imgs)\n",
    "        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "\n",
    "        targets = caps_sorted[:, 1:]\n",
    "\n",
    "        scores = pack_padded_sequence(scores, decode_lengths, batch_first=True).data\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "\n",
    "        loss = criterion(scores, targets)\n",
    "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "        decoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(decoder_optimizer, grad_clip)\n",
    "\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        top5 = accuracy(scores, targets, 5)\n",
    "        losses.update(loss.item(), sum(decode_lengths))\n",
    "        top5accs.update(top5, sum(decode_lengths))\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
    "                                                                          loss=losses,\n",
    "                                                                          top5=top5accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25909dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:23.021736Z",
     "iopub.status.busy": "2025-05-02T19:37:23.021513Z",
     "iopub.status.idle": "2025-05-02T19:37:23.027839Z",
     "shell.execute_reply": "2025-05-02T19:37:23.027247Z"
    },
    "papermill": {
     "duration": 0.013294,
     "end_time": "2025-05-02T19:37:23.029062",
     "exception": false,
     "start_time": "2025-05-02T19:37:23.015768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, encoder, decoder, criterion):\n",
    "    decoder.eval()  \n",
    "    if encoder is not None:\n",
    "        encoder.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top5accs = AverageMeter()\n",
    "\n",
    "    references = list()  \n",
    "    hypotheses = list()  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, caps, caplens, allcaps) in enumerate(val_loader):\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            caps = caps.to(device)\n",
    "            caplens = caplens.to(device)\n",
    "\n",
    "            if encoder is not None:\n",
    "                imgs = encoder(imgs)\n",
    "            scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "\n",
    "            targets = caps_sorted[:, 1:]\n",
    "\n",
    "            scores_copy = scores.clone()\n",
    "            scores = pack_padded_sequence(scores, decode_lengths, batch_first=True).data\n",
    "            targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "\n",
    "            loss = criterion(scores, targets)\n",
    "            loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "            losses.update(loss.item(), sum(decode_lengths))\n",
    "            top5 = accuracy(scores, targets, 5)\n",
    "            top5accs.update(top5, sum(decode_lengths))\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Validation: [{0}/{1}]\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader),\n",
    "                                                                                loss=losses, top5=top5accs))\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "358b1d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:23.039835Z",
     "iopub.status.busy": "2025-05-02T19:37:23.039581Z",
     "iopub.status.idle": "2025-05-02T19:37:23.043682Z",
     "shell.execute_reply": "2025-05-02T19:37:23.042885Z"
    },
    "papermill": {
     "duration": 0.010769,
     "end_time": "2025-05-02T19:37:23.044878",
     "exception": false,
     "start_time": "2025-05-02T19:37:23.034109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Создаем DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb5689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:23.055441Z",
     "iopub.status.busy": "2025-05-02T19:37:23.055188Z",
     "iopub.status.idle": "2025-05-02T19:37:23.059056Z",
     "shell.execute_reply": "2025-05-02T19:37:23.058283Z"
    },
    "papermill": {
     "duration": 0.010518,
     "end_time": "2025-05-02T19:37:23.060289",
     "exception": false,
     "start_time": "2025-05-02T19:37:23.049771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb_dim = 512 \n",
    "attention_dim = 512 \n",
    "decoder_dim = 512 \n",
    "dropout = 0.5\n",
    "\n",
    "epochs = 50  \n",
    "epochs_since_improvement = 0  \n",
    "decoder_lr = 4e-4  \n",
    "grad_clip = 5. \n",
    "alpha_c = 1. \n",
    "best_bleu4 = 0.  \n",
    "print_freq = 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81931b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:37:23.071318Z",
     "iopub.status.busy": "2025-05-02T19:37:23.071073Z",
     "iopub.status.idle": "2025-05-03T01:20:06.521646Z",
     "shell.execute_reply": "2025-05-03T01:20:06.520607Z"
    },
    "papermill": {
     "duration": 20563.45783,
     "end_time": "2025-05-03T01:20:06.523451",
     "exception": false,
     "start_time": "2025-05-02T19:37:23.065621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/288]\tLoss 8.7199 (8.7199)\tTop-5 Accuracy 0.169 (0.169)\n",
      "Epoch: [0][100/288]\tLoss 5.9053 (6.2492)\tTop-5 Accuracy 39.837 (37.217)\n",
      "Epoch: [0][200/288]\tLoss 5.7019 (6.0022)\tTop-5 Accuracy 41.109 (39.896)\n",
      "Validation: [0/32]\tLoss 5.5458 (5.5458)\tTop-5 Accuracy 43.617 (43.617)\t\n",
      "Epoch: [1][0/288]\tLoss 5.4870 (5.4870)\tTop-5 Accuracy 45.534 (45.534)\n",
      "Epoch: [1][100/288]\tLoss 5.6206 (5.5161)\tTop-5 Accuracy 41.831 (44.663)\n",
      "Epoch: [1][200/288]\tLoss 5.5148 (5.5026)\tTop-5 Accuracy 45.375 (44.775)\n",
      "Validation: [0/32]\tLoss 5.4323 (5.4323)\tTop-5 Accuracy 45.035 (45.035)\t\n",
      "Epoch: [2][0/288]\tLoss 5.2919 (5.2919)\tTop-5 Accuracy 48.596 (48.596)\n",
      "Epoch: [2][100/288]\tLoss 5.2819 (5.3510)\tTop-5 Accuracy 46.835 (46.482)\n",
      "Epoch: [2][200/288]\tLoss 5.4263 (5.3441)\tTop-5 Accuracy 46.283 (46.527)\n",
      "Validation: [0/32]\tLoss 5.3460 (5.3460)\tTop-5 Accuracy 45.567 (45.567)\t\n",
      "Epoch: [3][0/288]\tLoss 5.3484 (5.3484)\tTop-5 Accuracy 45.794 (45.794)\n",
      "Epoch: [3][100/288]\tLoss 5.4339 (5.2444)\tTop-5 Accuracy 45.572 (47.370)\n",
      "Epoch: [3][200/288]\tLoss 5.1616 (5.2389)\tTop-5 Accuracy 47.468 (47.640)\n",
      "Validation: [0/32]\tLoss 5.2727 (5.2727)\tTop-5 Accuracy 47.163 (47.163)\t\n",
      "Epoch: [4][0/288]\tLoss 4.9902 (4.9902)\tTop-5 Accuracy 52.126 (52.126)\n",
      "Epoch: [4][100/288]\tLoss 5.3462 (5.1436)\tTop-5 Accuracy 46.007 (48.697)\n",
      "Epoch: [4][200/288]\tLoss 5.2157 (5.1396)\tTop-5 Accuracy 47.295 (48.804)\n",
      "Validation: [0/32]\tLoss 5.2280 (5.2280)\tTop-5 Accuracy 47.695 (47.695)\t\n",
      "Epoch: [5][0/288]\tLoss 5.1202 (5.1202)\tTop-5 Accuracy 51.107 (51.107)\n",
      "Epoch: [5][100/288]\tLoss 5.2096 (5.0364)\tTop-5 Accuracy 48.375 (49.764)\n",
      "Epoch: [5][200/288]\tLoss 5.1056 (5.0458)\tTop-5 Accuracy 51.188 (49.663)\n",
      "Validation: [0/32]\tLoss 5.2061 (5.2061)\tTop-5 Accuracy 48.759 (48.759)\t\n",
      "Epoch: [6][0/288]\tLoss 4.8547 (4.8547)\tTop-5 Accuracy 51.706 (51.706)\n",
      "Epoch: [6][100/288]\tLoss 4.9797 (4.9365)\tTop-5 Accuracy 47.756 (50.594)\n",
      "Epoch: [6][200/288]\tLoss 4.8478 (4.9487)\tTop-5 Accuracy 51.448 (50.409)\n",
      "Validation: [0/32]\tLoss 5.1845 (5.1845)\tTop-5 Accuracy 49.645 (49.645)\t\n",
      "Epoch: [7][0/288]\tLoss 4.9963 (4.9963)\tTop-5 Accuracy 50.635 (50.635)\n",
      "Epoch: [7][100/288]\tLoss 4.9865 (4.8653)\tTop-5 Accuracy 49.222 (51.233)\n",
      "Epoch: [7][200/288]\tLoss 4.6150 (4.8760)\tTop-5 Accuracy 54.321 (51.120)\n",
      "Validation: [0/32]\tLoss 5.1764 (5.1764)\tTop-5 Accuracy 49.291 (49.291)\t\n",
      "Epoch: [8][0/288]\tLoss 4.9029 (4.9029)\tTop-5 Accuracy 50.929 (50.929)\n",
      "Epoch: [8][100/288]\tLoss 4.7259 (4.7583)\tTop-5 Accuracy 50.732 (52.107)\n",
      "Epoch: [8][200/288]\tLoss 4.8402 (4.7788)\tTop-5 Accuracy 51.418 (51.980)\n",
      "Validation: [0/32]\tLoss 5.1665 (5.1665)\tTop-5 Accuracy 49.291 (49.291)\t\n",
      "Epoch: [9][0/288]\tLoss 4.7202 (4.7202)\tTop-5 Accuracy 51.878 (51.878)\n",
      "Epoch: [9][100/288]\tLoss 4.8466 (4.6666)\tTop-5 Accuracy 50.929 (52.940)\n",
      "Epoch: [9][200/288]\tLoss 4.6868 (4.6785)\tTop-5 Accuracy 52.196 (52.898)\n",
      "Validation: [0/32]\tLoss 5.1919 (5.1919)\tTop-5 Accuracy 49.291 (49.291)\t\n",
      "Epoch: [10][0/288]\tLoss 4.4974 (4.4974)\tTop-5 Accuracy 54.620 (54.620)\n",
      "Epoch: [10][100/288]\tLoss 4.5876 (4.5751)\tTop-5 Accuracy 52.890 (53.799)\n",
      "Epoch: [10][200/288]\tLoss 4.6759 (4.5804)\tTop-5 Accuracy 52.439 (53.817)\n",
      "Validation: [0/32]\tLoss 5.1737 (5.1737)\tTop-5 Accuracy 48.582 (48.582)\t\n",
      "Epoch: [11][0/288]\tLoss 4.4664 (4.4664)\tTop-5 Accuracy 53.288 (53.288)\n",
      "Epoch: [11][100/288]\tLoss 4.6046 (4.4567)\tTop-5 Accuracy 53.501 (55.262)\n",
      "Epoch: [11][200/288]\tLoss 4.4019 (4.4738)\tTop-5 Accuracy 56.343 (55.040)\n",
      "Validation: [0/32]\tLoss 5.2508 (5.2508)\tTop-5 Accuracy 48.759 (48.759)\t\n",
      "Epoch: [12][0/288]\tLoss 4.2415 (4.2415)\tTop-5 Accuracy 57.471 (57.471)\n",
      "Epoch: [12][100/288]\tLoss 4.3322 (4.3433)\tTop-5 Accuracy 57.066 (56.404)\n",
      "Epoch: [12][200/288]\tLoss 4.5285 (4.3720)\tTop-5 Accuracy 55.036 (56.010)\n",
      "Validation: [0/32]\tLoss 5.3151 (5.3151)\tTop-5 Accuracy 47.163 (47.163)\t\n",
      "Epoch: [13][0/288]\tLoss 4.3264 (4.3264)\tTop-5 Accuracy 57.636 (57.636)\n",
      "Epoch: [13][100/288]\tLoss 4.3660 (4.2301)\tTop-5 Accuracy 54.302 (57.720)\n",
      "Epoch: [13][200/288]\tLoss 4.3040 (4.2529)\tTop-5 Accuracy 56.473 (57.452)\n",
      "Validation: [0/32]\tLoss 5.3471 (5.3471)\tTop-5 Accuracy 47.518 (47.518)\t\n",
      "Epoch: [14][0/288]\tLoss 4.2309 (4.2309)\tTop-5 Accuracy 56.743 (56.743)\n",
      "Epoch: [14][100/288]\tLoss 4.0094 (4.0978)\tTop-5 Accuracy 61.083 (59.358)\n",
      "Epoch: [14][200/288]\tLoss 4.1896 (4.1301)\tTop-5 Accuracy 58.685 (59.043)\n",
      "Validation: [0/32]\tLoss 5.3872 (5.3872)\tTop-5 Accuracy 47.872 (47.872)\t\n",
      "Epoch: [15][0/288]\tLoss 3.7490 (3.7490)\tTop-5 Accuracy 64.957 (64.957)\n",
      "Epoch: [15][100/288]\tLoss 4.0301 (3.9919)\tTop-5 Accuracy 59.091 (60.891)\n",
      "Epoch: [15][200/288]\tLoss 4.0293 (4.0139)\tTop-5 Accuracy 59.701 (60.578)\n",
      "Validation: [0/32]\tLoss 5.4447 (5.4447)\tTop-5 Accuracy 47.340 (47.340)\t\n",
      "Epoch: [16][0/288]\tLoss 3.8332 (3.8332)\tTop-5 Accuracy 63.834 (63.834)\n",
      "Epoch: [16][100/288]\tLoss 3.9587 (3.8636)\tTop-5 Accuracy 59.710 (62.822)\n",
      "Epoch: [16][200/288]\tLoss 3.8956 (3.8875)\tTop-5 Accuracy 59.901 (62.350)\n",
      "Validation: [0/32]\tLoss 5.5175 (5.5175)\tTop-5 Accuracy 44.504 (44.504)\t\n",
      "Epoch: [17][0/288]\tLoss 3.7166 (3.7166)\tTop-5 Accuracy 62.909 (62.909)\n",
      "Epoch: [17][100/288]\tLoss 3.7755 (3.7351)\tTop-5 Accuracy 61.525 (64.429)\n",
      "Epoch: [17][200/288]\tLoss 3.8080 (3.7628)\tTop-5 Accuracy 65.404 (64.217)\n",
      "Validation: [0/32]\tLoss 5.6063 (5.6063)\tTop-5 Accuracy 45.213 (45.213)\t\n",
      "Epoch: [18][0/288]\tLoss 3.7840 (3.7840)\tTop-5 Accuracy 62.326 (62.326)\n",
      "Epoch: [18][100/288]\tLoss 3.5050 (3.6194)\tTop-5 Accuracy 67.311 (66.476)\n",
      "Epoch: [18][200/288]\tLoss 3.6532 (3.6362)\tTop-5 Accuracy 65.565 (66.172)\n",
      "Validation: [0/32]\tLoss 5.7008 (5.7008)\tTop-5 Accuracy 43.085 (43.085)\t\n",
      "Epoch: [19][0/288]\tLoss 3.3930 (3.3930)\tTop-5 Accuracy 72.954 (72.954)\n",
      "Epoch: [19][100/288]\tLoss 3.4135 (3.4958)\tTop-5 Accuracy 70.299 (68.429)\n",
      "Epoch: [19][200/288]\tLoss 3.4667 (3.5184)\tTop-5 Accuracy 68.249 (68.085)\n",
      "Validation: [0/32]\tLoss 5.7586 (5.7586)\tTop-5 Accuracy 43.617 (43.617)\t\n",
      "Epoch: [20][0/288]\tLoss 3.3870 (3.3870)\tTop-5 Accuracy 70.942 (70.942)\n",
      "Epoch: [20][100/288]\tLoss 3.3950 (3.3857)\tTop-5 Accuracy 67.761 (70.138)\n",
      "Epoch: [20][200/288]\tLoss 3.5157 (3.3979)\tTop-5 Accuracy 65.968 (69.972)\n",
      "Validation: [0/32]\tLoss 5.9259 (5.9259)\tTop-5 Accuracy 42.199 (42.199)\t\n",
      "Epoch: [21][0/288]\tLoss 3.2065 (3.2065)\tTop-5 Accuracy 74.369 (74.369)\n",
      "Epoch: [21][100/288]\tLoss 3.1782 (3.2655)\tTop-5 Accuracy 72.177 (72.047)\n",
      "Epoch: [21][200/288]\tLoss 3.2154 (3.2854)\tTop-5 Accuracy 73.386 (71.793)\n",
      "Validation: [0/32]\tLoss 5.9739 (5.9739)\tTop-5 Accuracy 42.376 (42.376)\t\n",
      "Epoch: [22][0/288]\tLoss 3.0781 (3.0781)\tTop-5 Accuracy 75.090 (75.090)\n",
      "Epoch: [22][100/288]\tLoss 3.1783 (3.1443)\tTop-5 Accuracy 72.274 (74.033)\n",
      "Epoch: [22][200/288]\tLoss 3.2415 (3.1797)\tTop-5 Accuracy 72.504 (73.598)\n",
      "Validation: [0/32]\tLoss 6.0586 (6.0586)\tTop-5 Accuracy 42.021 (42.021)\t\n",
      "Epoch: [23][0/288]\tLoss 3.0650 (3.0650)\tTop-5 Accuracy 74.530 (74.530)\n",
      "Epoch: [23][100/288]\tLoss 2.9771 (3.0542)\tTop-5 Accuracy 77.487 (75.627)\n",
      "Epoch: [23][200/288]\tLoss 3.0732 (3.0730)\tTop-5 Accuracy 75.174 (75.263)\n",
      "Validation: [0/32]\tLoss 6.2393 (6.2393)\tTop-5 Accuracy 40.603 (40.603)\t\n",
      "Epoch: [24][0/288]\tLoss 3.0822 (3.0822)\tTop-5 Accuracy 76.360 (76.360)\n",
      "Epoch: [24][100/288]\tLoss 3.0270 (2.9595)\tTop-5 Accuracy 75.627 (77.263)\n",
      "Epoch: [24][200/288]\tLoss 2.9074 (2.9749)\tTop-5 Accuracy 78.709 (76.932)\n",
      "Validation: [0/32]\tLoss 6.2599 (6.2599)\tTop-5 Accuracy 40.603 (40.603)\t\n",
      "Epoch: [25][0/288]\tLoss 2.8335 (2.8335)\tTop-5 Accuracy 78.349 (78.349)\n",
      "Epoch: [25][100/288]\tLoss 2.8460 (2.8734)\tTop-5 Accuracy 80.068 (78.639)\n",
      "Epoch: [25][200/288]\tLoss 2.8968 (2.8884)\tTop-5 Accuracy 77.858 (78.325)\n",
      "Validation: [0/32]\tLoss 6.3781 (6.3781)\tTop-5 Accuracy 38.121 (38.121)\t\n",
      "Epoch: [26][0/288]\tLoss 2.8623 (2.8623)\tTop-5 Accuracy 80.450 (80.450)\n",
      "Epoch: [26][100/288]\tLoss 2.6936 (2.7775)\tTop-5 Accuracy 79.615 (80.297)\n",
      "Epoch: [26][200/288]\tLoss 2.9260 (2.7903)\tTop-5 Accuracy 78.146 (79.997)\n",
      "Validation: [0/32]\tLoss 6.4343 (6.4343)\tTop-5 Accuracy 39.716 (39.716)\t\n",
      "Epoch: [27][0/288]\tLoss 2.7638 (2.7638)\tTop-5 Accuracy 81.770 (81.770)\n",
      "Epoch: [27][100/288]\tLoss 2.6833 (2.7066)\tTop-5 Accuracy 81.441 (81.282)\n",
      "Epoch: [27][200/288]\tLoss 2.8919 (2.7169)\tTop-5 Accuracy 78.026 (81.085)\n",
      "Validation: [0/32]\tLoss 6.6240 (6.6240)\tTop-5 Accuracy 38.652 (38.652)\t\n",
      "Epoch: [28][0/288]\tLoss 2.4143 (2.4143)\tTop-5 Accuracy 85.277 (85.277)\n",
      "Epoch: [28][100/288]\tLoss 2.6484 (2.6052)\tTop-5 Accuracy 82.878 (82.850)\n",
      "Epoch: [28][200/288]\tLoss 2.6029 (2.6283)\tTop-5 Accuracy 82.585 (82.539)\n",
      "Validation: [0/32]\tLoss 6.6512 (6.6512)\tTop-5 Accuracy 38.121 (38.121)\t\n",
      "Epoch: [29][0/288]\tLoss 2.4513 (2.4513)\tTop-5 Accuracy 86.106 (86.106)\n",
      "Epoch: [29][100/288]\tLoss 2.5063 (2.5498)\tTop-5 Accuracy 84.014 (83.863)\n",
      "Epoch: [29][200/288]\tLoss 2.4910 (2.5588)\tTop-5 Accuracy 84.615 (83.641)\n",
      "Validation: [0/32]\tLoss 6.7465 (6.7465)\tTop-5 Accuracy 35.461 (35.461)\t\n",
      "Epoch: [30][0/288]\tLoss 2.4003 (2.4003)\tTop-5 Accuracy 85.666 (85.666)\n",
      "Epoch: [30][100/288]\tLoss 2.4171 (2.4623)\tTop-5 Accuracy 86.010 (85.124)\n",
      "Epoch: [30][200/288]\tLoss 2.5058 (2.4772)\tTop-5 Accuracy 81.939 (84.891)\n",
      "Validation: [0/32]\tLoss 6.8489 (6.8489)\tTop-5 Accuracy 35.284 (35.284)\t\n",
      "Epoch: [31][0/288]\tLoss 2.5467 (2.5467)\tTop-5 Accuracy 83.789 (83.789)\n",
      "Epoch: [31][100/288]\tLoss 2.3429 (2.3952)\tTop-5 Accuracy 86.130 (86.213)\n",
      "Epoch: [31][200/288]\tLoss 2.4369 (2.4079)\tTop-5 Accuracy 86.235 (85.947)\n",
      "Validation: [0/32]\tLoss 6.9377 (6.9377)\tTop-5 Accuracy 37.057 (37.057)\t\n",
      "Epoch: [32][0/288]\tLoss 2.3537 (2.3537)\tTop-5 Accuracy 86.180 (86.180)\n",
      "Epoch: [32][100/288]\tLoss 2.3518 (2.3250)\tTop-5 Accuracy 86.226 (87.234)\n",
      "Epoch: [32][200/288]\tLoss 2.3244 (2.3446)\tTop-5 Accuracy 86.170 (86.922)\n",
      "Validation: [0/32]\tLoss 7.0289 (7.0289)\tTop-5 Accuracy 36.348 (36.348)\t\n",
      "Epoch: [33][0/288]\tLoss 2.3053 (2.3053)\tTop-5 Accuracy 87.801 (87.801)\n",
      "Epoch: [33][100/288]\tLoss 2.2908 (2.2771)\tTop-5 Accuracy 86.557 (88.126)\n",
      "Epoch: [33][200/288]\tLoss 2.2483 (2.2841)\tTop-5 Accuracy 86.957 (87.898)\n",
      "Validation: [0/32]\tLoss 7.0629 (7.0629)\tTop-5 Accuracy 35.993 (35.993)\t\n",
      "Epoch: [34][0/288]\tLoss 2.1262 (2.1262)\tTop-5 Accuracy 88.889 (88.889)\n",
      "Epoch: [34][100/288]\tLoss 2.2268 (2.2105)\tTop-5 Accuracy 90.892 (88.839)\n",
      "Epoch: [34][200/288]\tLoss 2.1991 (2.2236)\tTop-5 Accuracy 87.692 (88.680)\n",
      "Validation: [0/32]\tLoss 7.1526 (7.1526)\tTop-5 Accuracy 34.397 (34.397)\t\n",
      "Epoch: [35][0/288]\tLoss 2.1566 (2.1566)\tTop-5 Accuracy 88.909 (88.909)\n",
      "Epoch: [35][100/288]\tLoss 2.0681 (2.1525)\tTop-5 Accuracy 90.947 (89.496)\n",
      "Epoch: [35][200/288]\tLoss 2.1367 (2.1617)\tTop-5 Accuracy 89.803 (89.377)\n",
      "Validation: [0/32]\tLoss 7.3373 (7.3373)\tTop-5 Accuracy 34.752 (34.752)\t\n",
      "Epoch: [36][0/288]\tLoss 1.9878 (1.9878)\tTop-5 Accuracy 90.388 (90.388)\n",
      "Epoch: [36][100/288]\tLoss 2.0514 (2.0967)\tTop-5 Accuracy 90.484 (90.461)\n",
      "Epoch: [36][200/288]\tLoss 2.0774 (2.1115)\tTop-5 Accuracy 90.630 (90.223)\n",
      "Validation: [0/32]\tLoss 7.3842 (7.3842)\tTop-5 Accuracy 36.525 (36.525)\t\n",
      "Epoch: [37][0/288]\tLoss 2.0237 (2.0237)\tTop-5 Accuracy 91.680 (91.680)\n",
      "Epoch: [37][100/288]\tLoss 2.0173 (2.0528)\tTop-5 Accuracy 92.351 (91.113)\n",
      "Epoch: [37][200/288]\tLoss 2.1077 (2.0619)\tTop-5 Accuracy 90.738 (90.950)\n",
      "Validation: [0/32]\tLoss 7.4758 (7.4758)\tTop-5 Accuracy 34.220 (34.220)\t\n",
      "Epoch: [38][0/288]\tLoss 2.0538 (2.0538)\tTop-5 Accuracy 91.549 (91.549)\n",
      "Epoch: [38][100/288]\tLoss 2.0419 (1.9908)\tTop-5 Accuracy 90.830 (91.942)\n",
      "Epoch: [38][200/288]\tLoss 2.1016 (2.0039)\tTop-5 Accuracy 90.772 (91.768)\n",
      "Validation: [0/32]\tLoss 7.4041 (7.4041)\tTop-5 Accuracy 32.979 (32.979)\t\n",
      "Epoch: [39][0/288]\tLoss 1.9258 (1.9258)\tTop-5 Accuracy 91.826 (91.826)\n",
      "Epoch: [39][100/288]\tLoss 1.8768 (1.9431)\tTop-5 Accuracy 92.446 (92.488)\n",
      "Epoch: [39][200/288]\tLoss 2.0740 (1.9583)\tTop-5 Accuracy 91.096 (92.240)\n",
      "Validation: [0/32]\tLoss 7.7063 (7.7063)\tTop-5 Accuracy 35.993 (35.993)\t\n",
      "Epoch: [40][0/288]\tLoss 1.8323 (1.8323)\tTop-5 Accuracy 94.435 (94.435)\n",
      "Epoch: [40][100/288]\tLoss 1.9007 (1.8979)\tTop-5 Accuracy 92.754 (93.170)\n",
      "Epoch: [40][200/288]\tLoss 1.9433 (1.9162)\tTop-5 Accuracy 92.129 (92.845)\n",
      "Validation: [0/32]\tLoss 7.6666 (7.6666)\tTop-5 Accuracy 35.993 (35.993)\t\n",
      "Epoch: [41][0/288]\tLoss 1.8327 (1.8327)\tTop-5 Accuracy 95.497 (95.497)\n",
      "Epoch: [41][100/288]\tLoss 1.8921 (1.8629)\tTop-5 Accuracy 92.257 (93.569)\n",
      "Epoch: [41][200/288]\tLoss 1.8856 (1.8687)\tTop-5 Accuracy 93.410 (93.429)\n",
      "Validation: [0/32]\tLoss 7.7657 (7.7657)\tTop-5 Accuracy 35.106 (35.106)\t\n",
      "Epoch: [42][0/288]\tLoss 1.8181 (1.8181)\tTop-5 Accuracy 94.697 (94.697)\n",
      "Epoch: [42][100/288]\tLoss 1.8644 (1.8199)\tTop-5 Accuracy 92.616 (94.062)\n",
      "Epoch: [42][200/288]\tLoss 1.9271 (1.8314)\tTop-5 Accuracy 93.827 (93.833)\n",
      "Validation: [0/32]\tLoss 7.7674 (7.7674)\tTop-5 Accuracy 35.284 (35.284)\t\n",
      "Epoch: [43][0/288]\tLoss 1.8459 (1.8459)\tTop-5 Accuracy 94.609 (94.609)\n",
      "Epoch: [43][100/288]\tLoss 1.7914 (1.7949)\tTop-5 Accuracy 94.590 (94.334)\n",
      "Epoch: [43][200/288]\tLoss 1.8990 (1.8023)\tTop-5 Accuracy 92.422 (94.250)\n",
      "Validation: [0/32]\tLoss 7.9259 (7.9259)\tTop-5 Accuracy 33.688 (33.688)\t\n",
      "Epoch: [44][0/288]\tLoss 1.7430 (1.7430)\tTop-5 Accuracy 94.138 (94.138)\n",
      "Epoch: [44][100/288]\tLoss 1.7627 (1.7609)\tTop-5 Accuracy 95.008 (94.680)\n",
      "Epoch: [44][200/288]\tLoss 1.7508 (1.7679)\tTop-5 Accuracy 94.536 (94.613)\n",
      "Validation: [0/32]\tLoss 7.8952 (7.8952)\tTop-5 Accuracy 32.092 (32.092)\t\n",
      "Epoch: [45][0/288]\tLoss 1.7135 (1.7135)\tTop-5 Accuracy 95.292 (95.292)\n",
      "Epoch: [45][100/288]\tLoss 1.6687 (1.7123)\tTop-5 Accuracy 95.057 (95.149)\n",
      "Epoch: [45][200/288]\tLoss 1.6688 (1.7245)\tTop-5 Accuracy 96.768 (95.058)\n",
      "Validation: [0/32]\tLoss 8.0233 (8.0233)\tTop-5 Accuracy 33.156 (33.156)\t\n",
      "Epoch: [46][0/288]\tLoss 1.6646 (1.6646)\tTop-5 Accuracy 96.140 (96.140)\n",
      "Epoch: [46][100/288]\tLoss 1.6904 (1.6860)\tTop-5 Accuracy 95.203 (95.514)\n",
      "Epoch: [46][200/288]\tLoss 1.7245 (1.6964)\tTop-5 Accuracy 94.291 (95.357)\n",
      "Validation: [0/32]\tLoss 8.0553 (8.0553)\tTop-5 Accuracy 35.461 (35.461)\t\n",
      "Epoch: [47][0/288]\tLoss 1.7125 (1.7125)\tTop-5 Accuracy 95.928 (95.928)\n",
      "Epoch: [47][100/288]\tLoss 1.7136 (1.6561)\tTop-5 Accuracy 96.043 (95.711)\n",
      "Epoch: [47][200/288]\tLoss 1.7919 (1.6659)\tTop-5 Accuracy 93.526 (95.659)\n",
      "Validation: [0/32]\tLoss 8.1636 (8.1636)\tTop-5 Accuracy 34.043 (34.043)\t\n",
      "Epoch: [48][0/288]\tLoss 1.6178 (1.6178)\tTop-5 Accuracy 96.007 (96.007)\n",
      "Epoch: [48][100/288]\tLoss 1.6518 (1.6264)\tTop-5 Accuracy 94.707 (95.995)\n",
      "Epoch: [48][200/288]\tLoss 1.6364 (1.6369)\tTop-5 Accuracy 95.408 (95.928)\n",
      "Validation: [0/32]\tLoss 8.2519 (8.2519)\tTop-5 Accuracy 34.929 (34.929)\t\n",
      "Epoch: [49][0/288]\tLoss 1.6013 (1.6013)\tTop-5 Accuracy 95.431 (95.431)\n",
      "Epoch: [49][100/288]\tLoss 1.6698 (1.6042)\tTop-5 Accuracy 94.504 (96.277)\n",
      "Epoch: [49][200/288]\tLoss 1.6976 (1.6093)\tTop-5 Accuracy 95.172 (96.186)\n",
      "Validation: [0/32]\tLoss 8.3020 (8.3020)\tTop-5 Accuracy 34.574 (34.574)\t\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
    "                               embed_dim=emb_dim,\n",
    "                               decoder_dim=decoder_dim,\n",
    "                               vocab_size=dataset.vocab_size,\n",
    "                               dropout=dropout)\n",
    "decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                     lr=decoder_lr)\n",
    "encoder = Encoder()\n",
    "\n",
    "decoder = decoder.to(device)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epochs_since_improvement == 20:\n",
    "        break\n",
    "    if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "        adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "\n",
    "    train(train_loader=train_loader,\n",
    "          encoder=encoder,\n",
    "          decoder=decoder,\n",
    "          criterion=criterion,\n",
    "          decoder_optimizer=decoder_optimizer,\n",
    "          epoch=epoch)\n",
    "\n",
    "    recent_bleu4 = validate(val_loader=val_loader,\n",
    "                            encoder=encoder,\n",
    "                            decoder=decoder,\n",
    "                            criterion=criterion)\n",
    "\n",
    "save_checkpoint('dota', epoch, epochs_since_improvement, encoder, decoder,\n",
    "                decoder_optimizer, recent_bleu4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae30133",
   "metadata": {
    "papermill": {
     "duration": 0.013508,
     "end_time": "2025-05-03T01:20:06.551505",
     "exception": false,
     "start_time": "2025-05-03T01:20:06.537997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Генерация комментариев"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6995316,
     "sourceId": 11413645,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 322450,
     "modelInstanceId": 301954,
     "sourceId": 363870,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20659.903264,
   "end_time": "2025-05-03T01:20:09.004302",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-02T19:35:49.101038",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
